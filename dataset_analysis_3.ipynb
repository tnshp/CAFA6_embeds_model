{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dae76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import obonet\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7fb792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>terms_predicted</th>\n",
       "      <th>terms_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A023FBW4</td>\n",
       "      <td>[GO:0019958, GO:0005576, GO:0043230, GO:001995...</td>\n",
       "      <td>[GO:0019958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023FBW7</td>\n",
       "      <td>[GO:0019957, GO:0005576, GO:0035716, GO:000560...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A023FDY8</td>\n",
       "      <td>[GO:0019957, GO:0005576, GO:0035716, GO:000560...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A023FF81</td>\n",
       "      <td>[GO:0019958, GO:0005576, GO:0043230, GO:001995...</td>\n",
       "      <td>[GO:0019958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A023FFB5</td>\n",
       "      <td>[GO:0047387, GO:0005674, GO:0008989, GO:000583...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82196</th>\n",
       "      <td>X2JI34</td>\n",
       "      <td>[GO:0009625, GO:0016102, GO:0009717, GO:004708...</td>\n",
       "      <td>[GO:0106223, GO:0051762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82197</th>\n",
       "      <td>X4Y2L4</td>\n",
       "      <td>[GO:0005765, GO:0009826, GO:0016798, GO:003021...</td>\n",
       "      <td>[GO:0033906, GO:0030214]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82198</th>\n",
       "      <td>X5JA13</td>\n",
       "      <td>[GO:0031267, GO:0000145, GO:0043066, GO:009754...</td>\n",
       "      <td>[GO:0009506, GO:0060321, GO:0000145, GO:000551...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82199</th>\n",
       "      <td>X5JB51</td>\n",
       "      <td>[GO:0031267, GO:0000145, GO:0043066, GO:009754...</td>\n",
       "      <td>[GO:0016020, GO:0009506, GO:0060321, GO:000014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82200</th>\n",
       "      <td>X5M5N0</td>\n",
       "      <td>[GO:0090188, GO:0045087, GO:0090279, GO:004866...</td>\n",
       "      <td>[GO:0140694, GO:0006972, GO:0006884, GO:005089...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qseqid                                    terms_predicted  \\\n",
       "0      A0A023FBW4  [GO:0019958, GO:0005576, GO:0043230, GO:001995...   \n",
       "1      A0A023FBW7  [GO:0019957, GO:0005576, GO:0035716, GO:000560...   \n",
       "2      A0A023FDY8  [GO:0019957, GO:0005576, GO:0035716, GO:000560...   \n",
       "3      A0A023FF81  [GO:0019958, GO:0005576, GO:0043230, GO:001995...   \n",
       "4      A0A023FFB5  [GO:0047387, GO:0005674, GO:0008989, GO:000583...   \n",
       "...           ...                                                ...   \n",
       "82196      X2JI34  [GO:0009625, GO:0016102, GO:0009717, GO:004708...   \n",
       "82197      X4Y2L4  [GO:0005765, GO:0009826, GO:0016798, GO:003021...   \n",
       "82198      X5JA13  [GO:0031267, GO:0000145, GO:0043066, GO:009754...   \n",
       "82199      X5JB51  [GO:0031267, GO:0000145, GO:0043066, GO:009754...   \n",
       "82200      X5M5N0  [GO:0090188, GO:0045087, GO:0090279, GO:004866...   \n",
       "\n",
       "                                              terms_true  \n",
       "0                                           [GO:0019958]  \n",
       "1                                           [GO:0019957]  \n",
       "2                                           [GO:0019957]  \n",
       "3                                           [GO:0019958]  \n",
       "4                                           [GO:0019957]  \n",
       "...                                                  ...  \n",
       "82196                           [GO:0106223, GO:0051762]  \n",
       "82197                           [GO:0033906, GO:0030214]  \n",
       "82198  [GO:0009506, GO:0060321, GO:0000145, GO:000551...  \n",
       "82199  [GO:0016020, GO:0009506, GO:0060321, GO:000014...  \n",
       "82200  [GO:0140694, GO:0006972, GO:0006884, GO:005089...  \n",
       "\n",
       "[82201 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_2_terms = pd.read_parquet(\"/mnt/d/ML/Kaggle/CAFA6-new/data_packet1/seq_2_terms.parquet\")\n",
    "seq_2_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfb4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82404, 2)\n",
      "Average number of terms per protein: 41.10\n",
      "Max number of terms for a protein: 761\n",
      "Max number of terms for a protein: 761\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entryID</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>{GO:0044238, GO:0051052, GO:0070647, GO:000548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3EC77</td>\n",
       "      <td>{GO:0031985, GO:0005794, GO:0012505, GO:003198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8IZR5</td>\n",
       "      <td>{GO:0005488, GO:0005515}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q8R2Z3</td>\n",
       "      <td>{GO:1902025, GO:0015701, GO:0022600, GO:000659...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P63027</td>\n",
       "      <td>{GO:0030139, GO:0043307, GO:0030136, GO:004690...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entryID                                              terms\n",
       "0  Q5W0B1  {GO:0044238, GO:0051052, GO:0070647, GO:000548...\n",
       "1  Q3EC77  {GO:0031985, GO:0005794, GO:0012505, GO:003198...\n",
       "2  Q8IZR5                           {GO:0005488, GO:0005515}\n",
       "3  Q8R2Z3  {GO:1902025, GO:0015701, GO:0022600, GO:000659...\n",
       "4  P63027  {GO:0030139, GO:0043307, GO:0030136, GO:004690..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_terms_grouped = pd.read_csv(\"/mnt/d/ML/Kaggle/CAFA6-new/CAFA6_dataset_generator/train_terms_grouped.tsv\", sep=\"\\t\")\n",
    "train_terms_grouped['terms'] = train_terms_grouped['terms'].str.split(';').apply(set)\n",
    "train_lens = train_terms_grouped['terms'].apply(len)\n",
    "print(train_terms_grouped.shape)\n",
    "print(f\"Average number of terms per protein: {train_lens.mean():.2f}\")\n",
    "print(f\"Max number of terms for a protein: {train_lens.max()}\")\n",
    "print(f\"Max number of terms for a protein: {train_lens.max()}\") \n",
    "train_terms_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6feae7",
   "metadata": {},
   "source": [
    "## Heirarchy proppgation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c773ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Parsing OBO Ontology...\n",
      "[2/3] Building Ancestor Map...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f123400784f4d8cb76d681f51df119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building ancestors:   0%|          | 0/40121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40125 GO terms from ontology\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# GO HIERARCHY UTILITIES\n",
    "# ==========================================\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_obo_parents(go_obo_path):\n",
    "    \"\"\"Parse GO ontology OBO file and extract parent relationships\"\"\"\n",
    "    print(f\"[1/3] Parsing OBO Ontology...\")\n",
    "    term_parents = defaultdict(set)\n",
    "    roots = set(['GO:0003674', 'GO:0008150', 'GO:0005575'])  # MF, BP, CC\n",
    "    \n",
    "    with open(go_obo_path, \"r\") as f:\n",
    "        cur_id = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"[Term]\":\n",
    "                cur_id = None\n",
    "            elif line.startswith(\"id: \"):\n",
    "                cur_id = line.split(\"id: \")[1].strip()\n",
    "            elif line.startswith(\"is_a: \"):\n",
    "                pid = line.split()[1].strip()\n",
    "                if cur_id:\n",
    "                    term_parents[cur_id].add(pid)\n",
    "            elif line.startswith(\"relationship: part_of \"):\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    pid = parts[2].strip()\n",
    "                    if cur_id:\n",
    "                        term_parents[cur_id].add(pid)\n",
    "    return term_parents, roots\n",
    "\n",
    "\n",
    "def get_ancestors_map(term_parents):\n",
    "    \"\"\"Build complete ancestors map for all terms\"\"\"\n",
    "    print(\"[2/3] Building Ancestor Map...\")\n",
    "    ancestors = {}\n",
    "    \n",
    "    def get_all_ancestors(term):\n",
    "        if term in ancestors:\n",
    "            return ancestors[term]\n",
    "        parents = term_parents.get(term, set())\n",
    "        all_anc = set(parents)\n",
    "        for p in parents:\n",
    "            all_anc |= get_all_ancestors(p)\n",
    "        ancestors[term] = all_anc\n",
    "        return all_anc\n",
    "    \n",
    "    for term in tqdm(list(term_parents.keys()), desc=\"Building ancestors\"):\n",
    "        get_all_ancestors(term)\n",
    "    return ancestors\n",
    "\n",
    "\n",
    "# Load GO ontology\n",
    "GO_OBO_PATH = '/mnt/d/ML/Kaggle/CAFA6/cafa-6-protein-function-prediction/Train/go-basic.obo'\n",
    "term_parents, roots = parse_obo_parents(GO_OBO_PATH)\n",
    "ancestors_map = get_ancestors_map(term_parents)\n",
    "print(f\"Loaded {len(ancestors_map)} GO terms from ontology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d25f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/3] Applying GO hierarchy constraint to terms_predicted...\n",
      "✓ GO hierarchy constraint applied to 82201 proteins\n",
      "\n",
      "After hierarchy propagation:\n",
      "Average number of predicted terms per protein: 854.73\n",
      "Max number of predicted terms for a protein: 1735\n",
      "Min number of predicted terms for a protein: 347\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# APPLY GO HIERARCHY CONSTRAINT\n",
    "# ==========================================\n",
    "print(\"[3/3] Applying GO hierarchy constraint to terms_predicted...\")\n",
    "\n",
    "def propagate_go_hierarchy(terms_set, ancestors_map, roots):\n",
    "    \"\"\"Propagate GO hierarchy: add all ancestors of predicted terms\"\"\"\n",
    "    if not isinstance(terms_set, set):\n",
    "        terms_set = set(terms_set) if terms_set else set()\n",
    "    \n",
    "    final_terms = set(terms_set)\n",
    "    \n",
    "    # Add all ancestors for each predicted term\n",
    "    for term in terms_set:\n",
    "        if term in ancestors_map:\n",
    "            final_terms.update(ancestors_map[term])\n",
    "    \n",
    "    # Optionally add root terms if any prediction exists\n",
    "    if len(final_terms) > 0:\n",
    "        final_terms.update(roots)\n",
    "    \n",
    "    return final_terms\n",
    "\n",
    "\n",
    "# Apply hierarchy constraint to each row\n",
    "seq_2_terms['terms_predicted'] = seq_2_terms['terms_predicted'].apply(\n",
    "    lambda x: propagate_go_hierarchy(x, ancestors_map, roots)\n",
    ")\n",
    "\n",
    "print(f\"✓ GO hierarchy constraint applied to {len(seq_2_terms)} proteins\")\n",
    "\n",
    "# Show statistics after propagation\n",
    "terms_len_after = seq_2_terms['terms_predicted'].apply(len)\n",
    "print(f\"\\nAfter hierarchy propagation:\")\n",
    "print(f\"Average number of predicted terms per protein: {terms_len_after.mean():.2f}\")\n",
    "print(f\"Max number of predicted terms for a protein: {terms_len_after.max()}\")\n",
    "print(f\"Min number of predicted terms for a protein: {terms_len_after.min()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bd088",
   "metadata": {},
   "source": [
    "## Check coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c90bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>terms_predicted</th>\n",
       "      <th>terms_true</th>\n",
       "      <th>train_terms_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A023FBW4</td>\n",
       "      <td>{GO:0009966, GO:0030029, GO:0052005, GO:004689...</td>\n",
       "      <td>[GO:0019958]</td>\n",
       "      <td>{GO:0019958, GO:0019956, GO:0005515, GO:001995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023FBW7</td>\n",
       "      <td>{GO:0150005, GO:0009966, GO:0042716, GO:000683...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "      <td>{GO:0019957, GO:0019956, GO:0005515, GO:001995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A023FDY8</td>\n",
       "      <td>{GO:0009966, GO:0160110, GO:0042127, GO:004271...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "      <td>{GO:0019957, GO:0019956, GO:0005515, GO:001995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A023FF81</td>\n",
       "      <td>{GO:0042692, GO:0102158, GO:0009966, GO:004275...</td>\n",
       "      <td>[GO:0019958]</td>\n",
       "      <td>{GO:0019958, GO:0019956, GO:0005515, GO:001995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A023FFB5</td>\n",
       "      <td>{GO:0001997, GO:0009966, GO:0000271, GO:004689...</td>\n",
       "      <td>[GO:0019957]</td>\n",
       "      <td>{GO:0019957, GO:0019956, GO:0005515, GO:001995...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qseqid                                    terms_predicted  \\\n",
       "0  A0A023FBW4  {GO:0009966, GO:0030029, GO:0052005, GO:004689...   \n",
       "1  A0A023FBW7  {GO:0150005, GO:0009966, GO:0042716, GO:000683...   \n",
       "2  A0A023FDY8  {GO:0009966, GO:0160110, GO:0042127, GO:004271...   \n",
       "3  A0A023FF81  {GO:0042692, GO:0102158, GO:0009966, GO:004275...   \n",
       "4  A0A023FFB5  {GO:0001997, GO:0009966, GO:0000271, GO:004689...   \n",
       "\n",
       "     terms_true                                    train_terms_all  \n",
       "0  [GO:0019958]  {GO:0019958, GO:0019956, GO:0005515, GO:001995...  \n",
       "1  [GO:0019957]  {GO:0019957, GO:0019956, GO:0005515, GO:001995...  \n",
       "2  [GO:0019957]  {GO:0019957, GO:0019956, GO:0005515, GO:001995...  \n",
       "3  [GO:0019958]  {GO:0019958, GO:0019956, GO:0005515, GO:001995...  \n",
       "4  [GO:0019957]  {GO:0019957, GO:0019956, GO:0005515, GO:001995...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(seq_2_terms, train_terms_grouped, left_on='qseqid', right_on='entryID', how='inner')\n",
    "merged_df.drop(columns=['entryID'], inplace=True)\n",
    "merged_df = merged_df.rename(columns={'terms': 'train_terms_all'})\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3edd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Coverage Analysis ===\n",
      "\n",
      "Overall Statistics:\n",
      "Average coverage: 97.20%\n",
      "Median coverage: 100.00%\n",
      "Min coverage: 0.00%\n",
      "Max coverage: 100.00%\n",
      "\n",
      "Rows with 100% coverage: 72159 / 82201\n",
      "Rows with 0% coverage: 11 / 82201\n",
      "\n",
      "Average missing terms per row: 1.07\n",
      "Total train terms checked: 3384649\n",
      "Total covered terms: 3296384\n",
      "Total missing terms: 88265\n"
     ]
    }
   ],
   "source": [
    "# Apply the check\n",
    "coverage_results = merged_df.apply(check_coverage, axis=1)\n",
    "coverage_df = pd.DataFrame(coverage_results.tolist())\n",
    "\n",
    "# Combine with original data\n",
    "analysis_df = pd.concat([merged_df, coverage_df], axis=1)\n",
    "\n",
    "print(\"=== Coverage Analysis ===\")\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"Average coverage: {coverage_df['coverage_pct'].mean():.2f}%\")\n",
    "print(f\"Median coverage: {coverage_df['coverage_pct'].median():.2f}%\")\n",
    "print(f\"Min coverage: {coverage_df['coverage_pct'].min():.2f}%\")\n",
    "print(f\"Max coverage: {coverage_df['coverage_pct'].max():.2f}%\")\n",
    "print(f\"\\nRows with 100% coverage: {(coverage_df['coverage_pct'] == 100).sum()} / {len(coverage_df)}\")\n",
    "print(f\"Rows with 0% coverage: {(coverage_df['coverage_pct'] == 0).sum()} / {len(coverage_df)}\")\n",
    "print(f\"\\nAverage missing terms per row: {coverage_df['missing_terms'].mean():.2f}\")\n",
    "print(f\"Total train terms checked: {coverage_df['total_train_terms'].sum()}\")\n",
    "print(f\"Total covered terms: {coverage_df['covered_terms'].sum()}\")\n",
    "print(f\"Total missing terms: {coverage_df['missing_terms'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e5294",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "merged_df['train_terms_all']  = merged_df['train_terms_all'].apply(list)\n",
    "\n",
    "term_to_aspect = np.load( \"/mnt/d/ML/Kaggle/CAFA6-new/data_packet1/go_term_to_aspect.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14595a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Filtering by aspect P\n",
      "Average number of terms per protein: 25.97\n",
      "Min number of terms for a protein: 0\n",
      "Max number of terms for a protein: 653\n",
      "No. of proteins with zero terms: 22340 / 82201 \n",
      "\n",
      "Average number of terms per protein: 576.08\n",
      "Min number of terms for a protein: 9\n",
      "Max number of terms for a protein: 1378\n",
      "=== Coverage Analysis ===\n",
      "\n",
      "Overall Statistics:\n",
      "Average coverage: 96.75%\n",
      "Median coverage: 100.00%\n",
      "Min coverage: 0.00%\n",
      "Max coverage: 100.00%\n",
      "\n",
      "Rows with 100% coverage: 52533 / 59861\n",
      "Rows with 0% coverage: 14 / 59861\n",
      "\n",
      "Average missing terms per row: 1.03\n",
      "Total train terms checked: 2135163\n",
      "Total covered terms: 2073482\n",
      "Total missing terms: 61681 \n",
      "\n",
      "\n",
      "############################################################\n",
      "Filtering by aspect C\n"
     ]
    }
   ],
   "source": [
    "#filter by aspect \n",
    "def filter_by_aspect(terms, aspect):\n",
    "    filtered_terms = {term for term in terms if term_to_aspect.get(term) == aspect}\n",
    "    return filtered_terms\n",
    "\n",
    "\n",
    "aspects = ['P', 'C', 'F']\n",
    "\n",
    "for aspect in aspects:\n",
    "\n",
    "    print(\"############################################################\")\n",
    "    print(f\"Filtering by aspect {aspect}\")\n",
    "    merged_df_copy = merged_df.copy()\n",
    "    merged_df_copy[f'terms_predicted'] = merged_df_copy['terms_predicted'].apply(lambda x: filter_by_aspect(x, aspect))\n",
    "    merged_df_copy[f'train_terms_all'] = merged_df_copy['train_terms_all'].apply(lambda x: filter_by_aspect(x, aspect))\n",
    "\n",
    "    \n",
    "    true_len = merged_df_copy['train_terms_all'].apply(len)\n",
    "    pred_len = merged_df_copy['terms_predicted'].apply(len)\n",
    "\n",
    "    zero_len_mask = (true_len == 0)\n",
    "    merged_df_copy = merged_df_copy[~zero_len_mask]\n",
    "    print(f\"Average number of terms per protein: {true_len.mean():.2f}\")\n",
    "    print(f\"Min number of terms for a protein: {true_len.min()}\")\n",
    "    print(f\"Max number of terms for a protein: {true_len.max()}\") \n",
    "    print(f\"No. of proteins with zero terms: {(true_len==0).sum()} / {len(true_len)} \\n\")\n",
    "\n",
    "    \n",
    "    print(f\"Average number of terms per protein: {pred_len.mean():.2f}\")\n",
    "    print(f\"Min number of terms for a protein: {pred_len.min()}\")\n",
    "    print(f\"Max number of terms for a protein: {pred_len.max()}\") \n",
    "\n",
    "\n",
    "    # Apply the check\n",
    "    coverage_results = merged_df_copy.apply(check_coverage, axis=1)\n",
    "    coverage_df = pd.DataFrame(coverage_results.tolist())\n",
    "\n",
    "    # Combine with original data\n",
    "    analysis_df = pd.concat([merged_df_copy, coverage_df], axis=1)\n",
    "\n",
    "    print(\"=== Coverage Analysis ===\")\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Average coverage: {coverage_df['coverage_pct'].mean():.2f}%\")\n",
    "    print(f\"Median coverage: {coverage_df['coverage_pct'].median():.2f}%\")\n",
    "    print(f\"Min coverage: {coverage_df['coverage_pct'].min():.2f}%\")\n",
    "    print(f\"Max coverage: {coverage_df['coverage_pct'].max():.2f}%\")\n",
    "    print(f\"\\nRows with 100% coverage: {(coverage_df['coverage_pct'] == 100).sum()} / {len(coverage_df)}\")\n",
    "    print(f\"Rows with 0% coverage: {(coverage_df['coverage_pct'] == 0).sum()} / {len(coverage_df)}\")\n",
    "    print(f\"\\nAverage missing terms per row: {coverage_df['missing_terms'].mean():.2f}\")\n",
    "    print(f\"Total train terms checked: {coverage_df['total_train_terms'].sum()}\")\n",
    "    print(f\"Total covered terms: {coverage_df['covered_terms'].sum()}\")\n",
    "    print(f\"Total missing terms: {coverage_df['missing_terms'].sum()} \\n\\n\")\n",
    "\n",
    "    del coverage_df\n",
    "    del merged_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325671b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Coverage Analysis ===\n",
      "\n",
      "Overall Statistics:\n",
      "Average coverage: 41.31%\n",
      "Median coverage: 50.00%\n",
      "Min coverage: 0.00%\n",
      "Max coverage: 100.00%\n",
      "\n",
      "Rows with 100% coverage: 7349 / 82201\n",
      "Rows with 0% coverage: 28145 / 82201\n",
      "\n",
      "Average missing terms per row: 2.55\n",
      "Total train terms checked: 467707\n",
      "Total covered terms: 258290\n",
      "Total missing terms: 209417\n"
     ]
    }
   ],
   "source": [
    "# Apply the check\n",
    "coverage_results = merged_df.apply(check_coverage, axis=1)\n",
    "coverage_df = pd.DataFrame(coverage_results.tolist())\n",
    "\n",
    "# Combine with original data\n",
    "analysis_df = pd.concat([merged_df, coverage_df], axis=1)\n",
    "\n",
    "print(\"=== Coverage Analysis ===\")\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"Average coverage: {coverage_df['coverage_pct'].mean():.2f}%\")\n",
    "print(f\"Median coverage: {coverage_df['coverage_pct'].median():.2f}%\")\n",
    "print(f\"Min coverage: {coverage_df['coverage_pct'].min():.2f}%\")\n",
    "print(f\"Max coverage: {coverage_df['coverage_pct'].max():.2f}%\")\n",
    "print(f\"\\nRows with 100% coverage: {(coverage_df['coverage_pct'] == 100).sum()} / {len(coverage_df)}\")\n",
    "print(f\"Rows with 0% coverage: {(coverage_df['coverage_pct'] == 0).sum()} / {len(coverage_df)}\")\n",
    "print(f\"\\nAverage missing terms per row: {coverage_df['missing_terms'].mean():.2f}\")\n",
    "print(f\"Total train terms checked: {coverage_df['total_train_terms'].sum()}\")\n",
    "print(f\"Total covered terms: {coverage_df['covered_terms'].sum()}\")\n",
    "print(f\"Total missing terms: {coverage_df['missing_terms'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970873b1",
   "metadata": {},
   "source": [
    "## ------Functions------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c237c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def print_size(data):\n",
    "    print(f'{sys.getsizeof(data) / (1024 * 1024):.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30638019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all true predictions from train_terms_all are present in terms_predicted\n",
    "def check_coverage(row):\n",
    "    \"\"\"Check what percentage of train_terms_all are in terms_predicted\"\"\"\n",
    "    # Check if train_terms_all is None or empty list\n",
    "    true_key  = 'train_terms_all'\n",
    "    if row[true_key] is None or (isinstance(row[true_key], list) and len(row[true_key]) == 0):\n",
    "        return None\n",
    "    \n",
    "    train_set = set(row[true_key])\n",
    "    pred_set = set(row['terms_predicted'])\n",
    "    \n",
    "    # Find terms in train_terms_all that are in terms_predicted\n",
    "    covered_terms = train_set.intersection(pred_set)\n",
    "    \n",
    "    # Calculate coverage percentage\n",
    "    coverage = len(covered_terms) / len(train_set) * 100 if len(train_set) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_train_terms': len(train_set),\n",
    "        'covered_terms': len(covered_terms),\n",
    "        'missing_terms': len(train_set) - len(covered_terms),\n",
    "        'coverage_pct': coverage,\n",
    "        'missing_term_list': list(train_set - covered_terms)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54b12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cafa6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
