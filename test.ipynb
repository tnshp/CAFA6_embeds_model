{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17107ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch \n",
    "from Dataset.Utils import prepare_data_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730ba1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_paths =  [\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/esm2_embeds_cafa5/train_embeddings.npy\",\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/protBERT_embeddings/train_embeddings.npy\",\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/t5_embeds/train_embeds.npy\"\n",
    "    ]\n",
    "ids_paths = [\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/esm2_embeds_cafa5/train_ids.npy\",\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/protBERT_embeddings/train_ids.npy\",\n",
    "      \"/mnt/d/ML/Kaggle/CAFA6-new/Dataset/t5_embeds/train_ids.npy\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ec7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeds shape: (142246, 1280), Ids shape: (142246,)\n",
      "Embeds shape: (142246, 1024), Ids shape: (142246,)\n",
      "Embeds shape: (142246, 1024), Ids shape: (142246,)\n",
      "Embeds shape: (142246, 1024), Ids shape: (142246,)\n",
      "Embeds shape: (142246, 1024), Ids shape: (142246,)\n"
     ]
    }
   ],
   "source": [
    "embeds_df_list = []\n",
    "\n",
    "for i in range(len(embeds_paths)):\n",
    "    embeds = np.load(embeds_paths[i], allow_pickle=True)\n",
    "    ids = np.load(ids_paths[i], allow_pickle=True)\n",
    "    print(f\"Embeds shape: {embeds.shape}, Ids shape: {ids.shape}\")\n",
    "    embeds_df = pd.DataFrame({\"EntryID\": ids, \"embed\": list(embeds)})\n",
    "    embeds_df_list.append(embeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433cc7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_df_list = None\n",
    "#collect garbage \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69e5c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.778234481811523"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#size in Mb\n",
    "sys.getsizeof(embeds_df_list[1]) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3731d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04948843, -0.03293516,  0.03247323, ..., -0.04353154,\n",
       "        0.0964628 ,  0.07306959], shape=(1024,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_df_list[2]['embed'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d5680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeds DF 1 shape: (142246, 2)\n",
      "Embeds DF 2 shape: (142246, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>concat_embed</th>\n",
       "      <th>embed_x</th>\n",
       "      <th>embed_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9ZSA8</td>\n",
       "      <td>[-0.092291094, -0.066283956, -0.01226195, 0.04...</td>\n",
       "      <td>[0.10063905, 0.019749707, 0.09575205, -0.19726...</td>\n",
       "      <td>[0.06355330348014832, 0.092497318983078, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P25353</td>\n",
       "      <td>[0.011624349, -0.030317612, -0.0058019715, 0.0...</td>\n",
       "      <td>[0.13231392, 0.06233021, 0.094939865, -0.14466...</td>\n",
       "      <td>[0.011784744448959827, -0.04589618742465973, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A2R8YCW8</td>\n",
       "      <td>[0.02737274, -0.041047025, -0.029205365, 0.028...</td>\n",
       "      <td>[0.14164767, 0.051090643, 0.0756673, -0.143788...</td>\n",
       "      <td>[0.030849341303110123, 0.03080468438565731, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G3V5N8</td>\n",
       "      <td>[0.033766113, -0.07888931, -0.05974137, 0.0456...</td>\n",
       "      <td>[0.13703091, 0.12680532, 0.117955275, -0.16379...</td>\n",
       "      <td>[-0.013897695578634739, 0.0360458567738533, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A140LFN4</td>\n",
       "      <td>[0.0119482, -0.002107593, -0.084922194, 0.0687...</td>\n",
       "      <td>[0.061685473, 0.050877817, 0.064081304, -0.150...</td>\n",
       "      <td>[-0.016684038564562798, 0.09142760932445526, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142241</th>\n",
       "      <td>O81299</td>\n",
       "      <td>[0.022891823, -0.06792282, -0.057677716, -0.03...</td>\n",
       "      <td>[0.14427365, 0.024739401, 0.094333366, -0.1877...</td>\n",
       "      <td>[0.04659712687134743, 0.09900099784135818, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142242</th>\n",
       "      <td>Q55AH8</td>\n",
       "      <td>[0.014263509, 0.033850852, 0.025951566, 0.0654...</td>\n",
       "      <td>[0.15403968, 0.03255585, 0.080744386, -0.14291...</td>\n",
       "      <td>[0.0451243557035923, -0.04376251623034477, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142243</th>\n",
       "      <td>Q80VK8</td>\n",
       "      <td>[0.03865814, 0.054107588, 0.07705976, 0.026639...</td>\n",
       "      <td>[0.14926998, 0.024992127, 0.07972684, -0.18500...</td>\n",
       "      <td>[0.00606992281973362, -0.05574773624539375, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142244</th>\n",
       "      <td>Q8IS12</td>\n",
       "      <td>[0.041082174, -0.020872245, 0.00023603393, 0.0...</td>\n",
       "      <td>[0.120118834, 0.10417359, 0.10750137, -0.15010...</td>\n",
       "      <td>[0.13251236081123352, 0.08502178639173508, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142245</th>\n",
       "      <td>P0AG74</td>\n",
       "      <td>[0.0018207595, -0.036250066, 0.04457826, -0.03...</td>\n",
       "      <td>[0.02316349, 0.010702979, 0.07081697, -0.18447...</td>\n",
       "      <td>[0.041519831866025925, -0.04246173053979874, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EntryID                                       concat_embed  \\\n",
       "0           Q9ZSA8  [-0.092291094, -0.066283956, -0.01226195, 0.04...   \n",
       "1           P25353  [0.011624349, -0.030317612, -0.0058019715, 0.0...   \n",
       "2       A0A2R8YCW8  [0.02737274, -0.041047025, -0.029205365, 0.028...   \n",
       "3           G3V5N8  [0.033766113, -0.07888931, -0.05974137, 0.0456...   \n",
       "4       A0A140LFN4  [0.0119482, -0.002107593, -0.084922194, 0.0687...   \n",
       "...            ...                                                ...   \n",
       "142241      O81299  [0.022891823, -0.06792282, -0.057677716, -0.03...   \n",
       "142242      Q55AH8  [0.014263509, 0.033850852, 0.025951566, 0.0654...   \n",
       "142243      Q80VK8  [0.03865814, 0.054107588, 0.07705976, 0.026639...   \n",
       "142244      Q8IS12  [0.041082174, -0.020872245, 0.00023603393, 0.0...   \n",
       "142245      P0AG74  [0.0018207595, -0.036250066, 0.04457826, -0.03...   \n",
       "\n",
       "                                                  embed_x  \\\n",
       "0       [0.10063905, 0.019749707, 0.09575205, -0.19726...   \n",
       "1       [0.13231392, 0.06233021, 0.094939865, -0.14466...   \n",
       "2       [0.14164767, 0.051090643, 0.0756673, -0.143788...   \n",
       "3       [0.13703091, 0.12680532, 0.117955275, -0.16379...   \n",
       "4       [0.061685473, 0.050877817, 0.064081304, -0.150...   \n",
       "...                                                   ...   \n",
       "142241  [0.14427365, 0.024739401, 0.094333366, -0.1877...   \n",
       "142242  [0.15403968, 0.03255585, 0.080744386, -0.14291...   \n",
       "142243  [0.14926998, 0.024992127, 0.07972684, -0.18500...   \n",
       "142244  [0.120118834, 0.10417359, 0.10750137, -0.15010...   \n",
       "142245  [0.02316349, 0.010702979, 0.07081697, -0.18447...   \n",
       "\n",
       "                                                  embed_y  \n",
       "0       [0.06355330348014832, 0.092497318983078, -0.02...  \n",
       "1       [0.011784744448959827, -0.04589618742465973, 0...  \n",
       "2       [0.030849341303110123, 0.03080468438565731, 0....  \n",
       "3       [-0.013897695578634739, 0.0360458567738533, 0....  \n",
       "4       [-0.016684038564562798, 0.09142760932445526, 0...  \n",
       "...                                                   ...  \n",
       "142241  [0.04659712687134743, 0.09900099784135818, 0.0...  \n",
       "142242  [0.0451243557035923, -0.04376251623034477, 0.0...  \n",
       "142243  [0.00606992281973362, -0.05574773624539375, -0...  \n",
       "142244  [0.13251236081123352, 0.08502178639173508, 0.0...  \n",
       "142245  [0.041519831866025925, -0.04246173053979874, 0...  \n",
       "\n",
       "[142246 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_df = None\n",
    "\n",
    "def concat_embeds(row):\n",
    "    embed1 = row['concat_embed']\n",
    "    embed2 = row['embed']\n",
    "    concat_embed = np.concatenate((embed1, embed2))\n",
    "    return concat_embed\n",
    "\n",
    "for i in range(1, len(embeds_df_list)):\n",
    "    print(f\"Embeds DF {i} shape: {embeds_df_list[i].shape}\")\n",
    "    if embeds_df is None:\n",
    "        embeds_df = embeds_df_list[i-1]\n",
    "        embeds_df_list[i-1] = None\n",
    "        embeds_df.rename(columns={\"embed\": 'concat_embed'}, inplace=True)\n",
    "    embeds_df = pd.merge(embeds_df, embeds_df_list[i], on=\"EntryID\", how='inner')\n",
    "    #delete merged df from list to save memory\n",
    "    embeds_df_list[i] = None\n",
    "    #concat embeddings\n",
    "    # embeds_df['concat_embed'] = embeds_df.apply(concat_embeds, axis=1)\n",
    "    # embeds_df.drop(columns=['embed'], inplace=True)\n",
    "\n",
    "embeds_df_list = None\n",
    "gc.collect()\n",
    "embeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd015e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = embeds_df['embed_y'].to_list()\n",
    "em = np.stack(em)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfeb08d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111.2969970703125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(em) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ad6132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401cb728",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#convert embeds column to np array\n",
    "cols = ['concat_embed', 'embed_x', 'embed_y']\n",
    "embeds =None\n",
    "for col in cols:\n",
    "    em = embeds_df[col].to_list()\n",
    "    em = np.stack(em)   \n",
    "    if embeds is None:\n",
    "        embeds = em \n",
    "    else:\n",
    "        embeds = np.concatenate([embeds, em], axis=1)\n",
    "    em = None\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f146a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10063905,  0.01974971,  0.09575205, ..., -0.04837033,\n",
       "        -0.01848502,  0.02100725],\n",
       "       [ 0.13231392,  0.06233021,  0.09493987, ..., -0.08690946,\n",
       "         0.00162027, -0.00218274],\n",
       "       [ 0.14164767,  0.05109064,  0.0756673 , ..., -0.09845898,\n",
       "        -0.03267479,  0.00680899],\n",
       "       ...,\n",
       "       [ 0.14926998,  0.02499213,  0.07972684, ..., -0.07171173,\n",
       "        -0.03229819,  0.0570601 ],\n",
       "       [ 0.12011883,  0.10417359,  0.10750137, ..., -0.07582046,\n",
       "         0.00545941, -0.00694445],\n",
       "       [ 0.02316349,  0.01070298,  0.07081697, ..., -0.01841847,\n",
       "        -0.04550426,  0.05292074]], shape=(142246, 1024), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds2 = embeds_df['embed_x'].to_list()\n",
    "embeds2 = np.stack(embeds2)\n",
    "embeds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559b567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555.6485595703125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(embeds2) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bed1126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P20536', 'O73864', 'O95231', ..., 'Q5RGB0', 'A0A2R8QMZ5',\n",
       "       'A0A8I6GHU0'], shape=(142246,), dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de619b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = np.load('/mnt/d/ML/Kaggle/CAFA6-new/Dataset/t5_embeds/train_embeds.npy')\n",
    "train_ids = np.load('/mnt/d/ML/Kaggle/CAFA6-new/Dataset/t5_embeds/train_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db764d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142246, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb15769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q9ZSA8</th>\n",
       "      <td>[-0.092291094, -0.066283956, -0.01226195, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P25353</th>\n",
       "      <td>[0.011624349, -0.030317612, -0.0058019715, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A2R8YCW8</th>\n",
       "      <td>[0.02737274, -0.041047025, -0.029205365, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3V5N8</th>\n",
       "      <td>[0.033766113, -0.07888931, -0.05974137, 0.0456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A140LFN4</th>\n",
       "      <td>[0.0119482, -0.002107593, -0.084922194, 0.0687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O81299</th>\n",
       "      <td>[0.022891823, -0.06792282, -0.057677716, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q55AH8</th>\n",
       "      <td>[0.014263509, 0.033850852, 0.025951566, 0.0654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q80VK8</th>\n",
       "      <td>[0.03865814, 0.054107588, 0.07705976, 0.026639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8IS12</th>\n",
       "      <td>[0.041082174, -0.020872245, 0.00023603393, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P0AG74</th>\n",
       "      <td>[0.0018207595, -0.036250066, 0.04457826, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142246 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        embed\n",
       "EntryID                                                      \n",
       "Q9ZSA8      [-0.092291094, -0.066283956, -0.01226195, 0.04...\n",
       "P25353      [0.011624349, -0.030317612, -0.0058019715, 0.0...\n",
       "A0A2R8YCW8  [0.02737274, -0.041047025, -0.029205365, 0.028...\n",
       "G3V5N8      [0.033766113, -0.07888931, -0.05974137, 0.0456...\n",
       "A0A140LFN4  [0.0119482, -0.002107593, -0.084922194, 0.0687...\n",
       "...                                                       ...\n",
       "O81299      [0.022891823, -0.06792282, -0.057677716, -0.03...\n",
       "Q55AH8      [0.014263509, 0.033850852, 0.025951566, 0.0654...\n",
       "Q80VK8      [0.03865814, 0.054107588, 0.07705976, 0.026639...\n",
       "Q8IS12      [0.041082174, -0.020872245, 0.00023603393, 0.0...\n",
       "P0AG74      [0.0018207595, -0.036250066, 0.04457826, -0.03...\n",
       "\n",
       "[142246 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_df = pd.DataFrame({\"EntryID\": train_ids, \"embed\": list(train_embeds)})\n",
    "embeds_df = embeds_df.set_index('EntryID')\n",
    "# print(embeds_df['EntryID'].nunique())\n",
    "embeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649a40b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>GO:0000785</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>GO:0004842</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>GO:0051865</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>GO:0006275</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5W0B1</td>\n",
       "      <td>GO:0006513</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537022</th>\n",
       "      <td>Q06667</td>\n",
       "      <td>GO:0070481</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537023</th>\n",
       "      <td>B1NF19</td>\n",
       "      <td>GO:0033075</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537024</th>\n",
       "      <td>B1NF19</td>\n",
       "      <td>GO:0047052</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537025</th>\n",
       "      <td>B1NF19</td>\n",
       "      <td>GO:0047056</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537026</th>\n",
       "      <td>B1NF19</td>\n",
       "      <td>GO:0102632</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537027 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EntryID        term aspect\n",
       "0       Q5W0B1  GO:0000785      C\n",
       "1       Q5W0B1  GO:0004842      F\n",
       "2       Q5W0B1  GO:0051865      P\n",
       "3       Q5W0B1  GO:0006275      P\n",
       "4       Q5W0B1  GO:0006513      P\n",
       "...        ...         ...    ...\n",
       "537022  Q06667  GO:0070481      P\n",
       "537023  B1NF19  GO:0033075      P\n",
       "537024  B1NF19  GO:0047052      F\n",
       "537025  B1NF19  GO:0047056      F\n",
       "537026  B1NF19  GO:0102632      F\n",
       "\n",
       "[537027 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_terms_df = pd.read_csv(\"/mnt/d/ML/Kaggle/CAFA6/cafa-6-protein-function-prediction/Train/train_terms.tsv\",\n",
    "                    delimiter='\\t')\n",
    "train_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d148b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data_range(train_terms_df, embeds_df, [0, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd49f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Utils.tokenizer import nearly_orthogonal_vectors\n",
    "\n",
    "class EmbedTokenizer(nn.Module):\n",
    "    def __init__(self, D, d, N, rng=None):  \n",
    "        super(EmbedTokenizer, self).__init__()\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        D : int\n",
    "            Dimension of the embedding space.\n",
    "        d : int\n",
    "            Dimension of the token space.\n",
    "        N : int\n",
    "            Number of tokens.\n",
    "        rng : np.random.Generator or None\n",
    "            Random generator. If None, use default.\n",
    "        \"\"\"\n",
    "        if rng is None:\n",
    "            rng = np.random.default_rng()\n",
    "\n",
    "        K = D\n",
    "        V = nearly_orthogonal_vectors(D, K, tol=0.01, max_tries=100, rng=rng)\n",
    "        \n",
    "        P = []\n",
    "\n",
    "        for i in range(N):\n",
    "            indices = np.arange(K)\n",
    "            sampled_idx = np.random.choice(indices, size=d, replace=False)\n",
    "            p = V[sampled_idx]\n",
    "            P.append(torch.tensor(p, dtype=torch.float32))\n",
    "        \n",
    "        # Stack all P matrices into a single tensor: (N, d, D)\n",
    "        self.P = torch.stack(P)\n",
    "        self.register_buffer('P_buffer', self.P)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor, shape (batch_size, D) or (D,)\n",
    "            Input embeddings.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tokens : Tensor, shape (batch_size, N, d) or (N, d)\n",
    "            Token representations.\n",
    "        \"\"\"\n",
    "        # Handle both single sample and batch\n",
    "        squeeze_output = False\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)  # (1, D)\n",
    "            squeeze_output = True\n",
    "        \n",
    "        batch_size, D = x.shape\n",
    "        \n",
    "        # Get P and move to correct device/dtype\n",
    "        P = self.P_buffer.to(dtype=x.dtype, device=x.device)  # (N, d, D)\n",
    "\n",
    "        # Reshape P to 2D: (D, N*d) and compute in one matmul to ensure batch dim is first\n",
    "        P_2d = P.permute(2, 0, 1).reshape(D, -1)  # (D, N*d)\n",
    "        tokens = torch.matmul(x, P_2d)  # (batch_size, N*d)\n",
    "        tokens = tokens.reshape(batch_size, P.shape[0], P.shape[1])  # (batch_size, N, d)\n",
    "\n",
    "        if squeeze_output:\n",
    "            tokens = tokens.squeeze(0)  # Remove batch dimension if input was 1D\n",
    "        \n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac2ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EmbeddingsDataset():\n",
    "    def __init__(self, data, oversample_indices=None):\n",
    "        self.data = data\n",
    "        self.oversample_indices = oversample_indices if oversample_indices is not None else list(range(len(self.data['embeds'])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.oversample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.oversample_indices[idx]\n",
    "\n",
    "        return {\n",
    "            'entryID': self.data['entries'][sample_idx],\n",
    "            'embeds' : self.data['embeds'][sample_idx],\n",
    "            'label' : self.data['labels'][sample_idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8725867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "tokens shape: torch.Size([32, 64, 256])\n",
      "labels shape : torch.Size([32, 64])\n",
      "time (single batch): 0.0079s\n"
     ]
    }
   ],
   "source": [
    "# Tokenized dataset + collate that runs embeddings through the tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class TokenizedEmbeddingsDataset(Dataset):\n",
    "    \"\"\"Dataset that yields raw embeddings; tokenization is done in collate_fn for batching.\"\"\"\n",
    "    def __init__(self, data, oversample_indices=None):\n",
    "        self.data = data\n",
    "        self.oversample_indices = oversample_indices if oversample_indices is not None else list(range(len(self.data['embeds'])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.oversample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.oversample_indices[idx]\n",
    "        return {\n",
    "            'entryID': self.data['entries'][sample_idx],\n",
    "            'embed': self.data['embeds'][sample_idx],\n",
    "            'label': self.data['labels'][sample_idx]\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_tokenize(batch, tokenizer, device=None, dtype=torch.float32):\n",
    "    \"\"\"Batch raw embeds, move to device, run tokenizer once for the batch.\n",
    "\n",
    "    Returns a dict with keys: 'entryID' (list), 'tokens' (Tensor: batch,N,d), 'label' (Tensor)\n",
    "    \"\"\"\n",
    "    embeds = [item['embed'] for item in batch]\n",
    "    # stack into (batch_size, D)\n",
    "    embeds = np.stack(embeds)\n",
    "    embeds = torch.tensor(embeds, dtype=dtype)\n",
    "    if device is not None:\n",
    "        embeds = embeds.to(device)\n",
    "\n",
    "    # ensure tokenizer is on the requested device\n",
    "    try:\n",
    "        tokenizer_device = next(tokenizer.parameters()).device\n",
    "    except StopIteration:\n",
    "        # tokenizer may have no parameters; attempt P_buffer or default to cpu\n",
    "        tokenizer_device = getattr(tokenizer, 'P_buffer', torch.tensor(0)).device if hasattr(tokenizer, 'P_buffer') else torch.device('cpu')\n",
    "\n",
    "    if device is not None and tokenizer_device != device:\n",
    "        try:\n",
    "            tokenizer = tokenizer.to(device)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(embeds)  # expected (batch_size, N, d)\n",
    "\n",
    "    # Fix swapped axes if tokenizer produced (N, batch_size, d)\n",
    "    try:\n",
    "        if hasattr(tokenizer, 'P_buffer') and isinstance(tokenizer.P_buffer, torch.Tensor):\n",
    "            N = tokenizer.P_buffer.shape[0]\n",
    "            if tokens.dim() == 3 and tokens.shape[0] == N and tokens.shape[1] != N:\n",
    "                tokens = tokens.permute(1, 0, 2).contiguous()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Convert labels to numpy array first to avoid slow list->tensor warning\n",
    "    labels_np = np.array([item['label'] for item in batch])\n",
    "    labels = torch.tensor(labels_np, dtype=torch.long)\n",
    "\n",
    "    entryIDs = [item['entryID'] for item in batch]\n",
    "\n",
    "    return {'entryID': entryIDs, 'tokens': tokens, 'label': labels}\n",
    "\n",
    "\n",
    "class PrefetchLoader:\n",
    "    \"\"\"DataLoader wrapper that asynchronously preloads next batch to CUDA.\n",
    "\n",
    "    Use like: prefetch_loader = PrefetchLoader(loader, device)\n",
    "    for batch in prefetch_loader:\n",
    "        # batch already moved to device (if CUDA)\n",
    "\n",
    "    Notes:\n",
    "    - Works only when `device` is CUDA; otherwise yields batches unchanged.\n",
    "    - Requires that collate_fn returns torch tensors (tokens/label).\n",
    "    \"\"\"\n",
    "    def __init__(self, loader, device):\n",
    "        self.loader = loader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.loader_iter = iter(self.loader)\n",
    "        if self.device.type == 'cuda':\n",
    "            self.stream = torch.cuda.Stream()\n",
    "            self._preload()\n",
    "        else:\n",
    "            self.next_batch = None\n",
    "        return self\n",
    "\n",
    "    def _preload(self):\n",
    "        try:\n",
    "            self.next_batch = next(self.loader_iter)\n",
    "        except StopIteration:\n",
    "            self.next_batch = None\n",
    "            return\n",
    "        # move tensors to device asynchronously\n",
    "        if self.device.type == 'cuda':\n",
    "            with torch.cuda.stream(self.stream):\n",
    "                for k, v in list(self.next_batch.items()):\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        # non_blocking requires pinned memory on CPU side\n",
    "                        # If tensor already on CUDA, .cuda() will be a no-op on same device\n",
    "                        self.next_batch[k] = v.cuda(non_blocking=True)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.device.type == 'cuda':\n",
    "            if self.next_batch is None:\n",
    "                raise StopIteration\n",
    "            # wait for copy stream\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            batch = self.next_batch\n",
    "            # preload next\n",
    "            self._preload()\n",
    "            return batch\n",
    "        else:\n",
    "            # CPU path: just yield from underlying loader\n",
    "            return next(self.loader_iter)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# If `tokenizer` is not defined in the notebook, try to instantiate one from the class\n",
    "if 'tokenizer' not in globals():\n",
    "    try:\n",
    "        D = int(np.asarray(data['embeds'][0]).shape[0])\n",
    "    except Exception:\n",
    "        raise RuntimeError('Cannot determine embed dimension from `data`. Make sure `data` is prepared.')\n",
    "    try:\n",
    "        # try to instantiate EmbedTokenizer if available\n",
    "        tokenizer = EmbedTokenizer(D=D, d=256, N=64)\n",
    "        print('Created EmbedTokenizer with D=', D)\n",
    "    except Exception:\n",
    "        # fallback simple tokenizer\n",
    "        class SimpleTokenizer(torch.nn.Module):\n",
    "            def __init__(self, D, d=256, N=100):\n",
    "                super().__init__()\n",
    "                # random projection stored as buffer\n",
    "                proj = torch.randn(N, d, D)\n",
    "                self.register_buffer('proj', proj)\n",
    "            def forward(self, x):\n",
    "                return torch.matmul(x, self.proj.transpose(-1, -2))\n",
    "        tokenizer = SimpleTokenizer(D)\n",
    "        print('Using fallback SimpleTokenizer')\n",
    "\n",
    "# Move tokenizer to device\n",
    "try:\n",
    "    tokenizer = tokenizer.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Build DataLoader: do NOT pin_memory because collate moves tensors to device already\n",
    "dataset = TokenizedEmbeddingsDataset(data)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=False, collate_fn=lambda b: collate_tokenize(b, tokenizer, device))\n",
    "\n",
    "# Wrap with PrefetchLoader when using CUDA\n",
    "if device.type == 'cuda':\n",
    "    prefetch_loader = PrefetchLoader(loader, device)\n",
    "    iter_loader = iter(prefetch_loader)\n",
    "else:\n",
    "    iter_loader = iter(loader)\n",
    "\n",
    "# quick sanity check & timing\n",
    "start = time.time()\n",
    "try:\n",
    "    batch = next(iter_loader)\n",
    "    elapsed = time.time() - start\n",
    "    print('tokens shape:', batch['tokens'].shape)\n",
    "    print('labels shape :', batch['label'].shape)\n",
    "    print(f'time (single batch): {elapsed:.4f}s')\n",
    "except Exception as e:\n",
    "    print('Error when iterating loader:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436f17f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "C_in = tokenizer.P.shape[1]  # token dimension d\n",
    "\n",
    "model = Query2Label(\n",
    "    num_classes=num_classes,\n",
    "    in_dim=C_in,\n",
    "    nheads=8,\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "# quick forward pass test\n",
    "\n",
    "batch = next(iter_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(batch['tokens'])\n",
    "    print('logits shape:', logits.shape)  # expected (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755efa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cafa6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
